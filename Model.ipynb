{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10678598,"sourceType":"datasetVersion","datasetId":6614988},{"sourceId":11420734,"sourceType":"datasetVersion","datasetId":6567143}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### XLM Roberta fine tuning","metadata":{}},{"cell_type":"code","source":"!pip install nlpaug\n!pip install ktrain\n!pip install tensorflow\n!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:53:15.561868Z","iopub.execute_input":"2025-03-26T18:53:15.562218Z","iopub.status.idle":"2025-03-26T18:53:52.194386Z","shell.execute_reply.started":"2025-03-26T18:53:15.562189Z","shell.execute_reply":"2025-03-26T18:53:52.193282Z"}},"outputs":[{"name":"stdout","text":"Collecting nlpaug\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.26.4)\nRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.2.3)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.32.3)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.17.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.16.2->nlpaug) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.6)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.2->nlpaug) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\nCollecting ktrain\n  Downloading ktrain-0.41.4.tar.gz (25.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\nRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.5)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.2.3)\nRequirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.32.3)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.4.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ktrain) (24.2)\nCollecting langdetect (from ktrain)\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.4.1)\nRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\nCollecting syntok>1.3.3 (from ktrain)\n  Downloading syntok-1.4.4-py3-none-any.whl.metadata (10 kB)\nCollecting tika (from ktrain)\n  Downloading tika-3.1.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from ktrain) (4.47.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.2.0)\nCollecting keras_bert>=0.86.0 (from ktrain)\n  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting whoosh (from ktrain)\n  Downloading Whoosh-2.7.4-py2.py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_bert>=0.86.0->ktrain) (1.26.4)\nCollecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2025.1)\nRequirement already satisfied: regex>2016 in /usr/local/lib/python3.10/dist-packages (from syntok>1.3.3->ktrain) (2024.11.6)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->ktrain) (1.17.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ktrain) (2025.1.31)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.13.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.5.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika->ktrain) (75.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.29.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (6.0.2)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->ktrain) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers->ktrain) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers->ktrain) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->keras_bert>=0.86.0->ktrain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->keras_bert>=0.86.0->ktrain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->keras_bert>=0.86.0->ktrain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->keras_bert>=0.86.0->ktrain) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->keras_bert>=0.86.0->ktrain) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->keras_bert>=0.86.0->ktrain) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->keras_bert>=0.86.0->ktrain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->keras_bert>=0.86.0->ktrain) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->keras_bert>=0.86.0->ktrain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->keras_bert>=0.86.0->ktrain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->keras_bert>=0.86.0->ktrain) (2024.2.0)\nDownloading syntok-1.4.4-py3-none-any.whl (24 kB)\nDownloading tika-3.1.0-py3-none-any.whl (38 kB)\nDownloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect\n  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for ktrain: filename=ktrain-0.41.4-py3-none-any.whl size=25316932 sha256=9e88978f4428574a35e15a16278f036641d3c8a31fd46e58c7ddb50027e13a42\n  Stored in directory: /root/.cache/pip/wheels/fa/6a/9c/8a873b38bbd8bc207d33c64726bd18f7ef85f8e70dc3ac2e4b\n  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33500 sha256=e942bf60b268c068700bbb1866bff8c47d25f357bc627cb4b0237935e3d82fdd\n  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12285 sha256=aa4c2ef37c709933352c85235a49db9995ca155f0a58a9924d60f118c1912e80\n  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3944 sha256=740f65ad5a6e40632bf6a694911f075ad68eb6412e106b1d6521987983aa23a1\n  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4654 sha256=32226fdd045cfb7f5c20767e55ce7fc0af012e1434bf0abec408461313fea359\n  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14974 sha256=ad1b5585a7a2d11a9a9321226c7f160083f43b1514226c3b719eeedde330ad40\n  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6945 sha256=357f7a35924116de0da8ef7d0ccb067b46e0fb863051ddd071519f72c5b7fc3b\n  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4970 sha256=948f2e92a12d18a52bf307c24ac8329e5608c2aa9041744ccc11f56a44a0e7b3\n  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=10ffc3421890ab54eba936627439d48700e568dc1cdf7233d51bc421ad4c0967\n  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=c73a7a75191019f76fdf401b51abee31264909890e5069153deb96c95a1c0b36\n  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\nSuccessfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect\nInstalling collected packages: whoosh, syntok, langdetect, tika, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, keras-transformer, keras_bert, ktrain\nSuccessfully installed keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.41.4 langdetect-1.0.9 syntok-1.4.4 tika-3.1.0 whoosh-2.7.4\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport re\nimport string\nfrom sklearn.model_selection import train_test_split\nfrom transformers import RobertaTokenizer, TFRobertaForSequenceClassification\nimport nlpaug.augmenter.word as naw\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:55:16.911165Z","iopub.execute_input":"2025-03-26T18:55:16.911518Z","iopub.status.idle":"2025-03-26T18:56:02.787743Z","shell.execute_reply.started":"2025-03-26T18:55:16.911491Z","shell.execute_reply":"2025-03-26T18:56:02.786827Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"path = '/kaggle/input/multibully/Cyberbully_corrected_emotion_sentiment.xlsx - cyberbully.csv'\ndf = pd.read_csv(path )\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:07:28.324806Z","iopub.execute_input":"2025-03-06T09:07:28.325539Z","iopub.status.idle":"2025-03-06T09:07:28.411392Z","shell.execute_reply.started":"2025-03-06T09:07:28.325504Z","shell.execute_reply":"2025-03-06T09:07:28.410401Z"}},"outputs":[{"name":"stdout","text":"  Img-Name                                           Img-Text Img-Text-Label  \\\n0    0.jpg  Shivam @shivamishraa Girls be named naina and ...          Bully   \n1    1.jpg  Aaloo ke paranthe is the best breakfast Omelet...       Nonbully   \n2    2.jpg     For Boyfriend For Bestfriend DESI ADUKT TROLLS          Bully   \n3    3.jpg  You find a new YouTuber He's funny All of his ...       Nonbully   \n4    4.jpg  not_shubham14 @mentally_dank Kids at Marine Dr...          Bully   \n\n  Img-Label Text-Label Sentiment   Emotion Sarcasm      Harmful-Score  \\\n0  Nonbully      Bully  Negative   Disgust     Yes  Partially-Harmful   \n1  Nonbully   Nonbully   Neutral     Other      No           Harmless   \n2     Bully   Nonbully  Negative  Ridicule      No  Partially-Harmful   \n3  Nonbully   Nonbully   Neutral   Sadness      No           Harmless   \n4  Nonbully   Nonbully  Negative   Sadness      No  Partially-Harmful   \n\n       Target  ... Unnamed: 14 Unnamed: 15 Unnamed: 16  Unnamed: 17     Bully  \\\n0  Individual  ...         NaN         NaN         NaN          NaN  Nonbully   \n1         NaN  ...         NaN         NaN         NaN          NaN       NaN   \n2     Society  ...         NaN         NaN         NaN          NaN       NaN   \n3         NaN  ...         NaN         NaN         NaN          NaN       NaN   \n4  Individual  ...         NaN         NaN         NaN          NaN       NaN   \n\n   Negative  Happiness  Yes           Harmless    Individual  \n0   Neutral    Sadness   No  Partially-Harmful  Organization  \n1  Positive       Fear  NaN       Very-Harmful     Community  \n2       NaN    Disgust  NaN                NaN       Society  \n3       NaN      Angry  NaN                NaN           NaN  \n4       NaN      Trust  NaN                NaN           NaN  \n\n[5 rows x 24 columns]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport string\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'\\[.*?\\]', '', text)  \n    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) \n    text = re.sub(r'\\w*\\d\\w*', '', text)  \n    return text\ndf['Img-Text'] = df['Img-Text'].astype(str).apply(clean_text)\nunwanted_labels = ['|', '11', '22', '32', '21']\ndf = df[~df['Text-Label'].isin(unwanted_labels)]\nlabel_mapping = {\"Bully\": 1, \"Nonbully\": 0}\ndf['Text-Label'] = df['Text-Label'].map(label_mapping)\ndf.dropna(subset=['Text-Label'], inplace=True)\ndf = df.drop_duplicates(subset='Img-Text', keep='first')\ndf.reset_index(drop=True, inplace=True)\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T18:53:08.227938Z","iopub.execute_input":"2025-03-26T18:53:08.228256Z","iopub.status.idle":"2025-03-26T18:53:08.253329Z","shell.execute_reply.started":"2025-03-26T18:53:08.228231Z","shell.execute_reply":"2025-03-26T18:53:08.252168Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-b32c6ce48059>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\w*\\d\\w*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Img-Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Img-Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0munwanted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'11'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'22'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'21'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text-Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munwanted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"import nltk\nimport os\nimport shutil\nimport zipfile\nnltk.download('wordnet', download_dir='/kaggle/working/nltk_data')\nnltk.download('omw-1.4', download_dir='/kaggle/working/nltk_data')\nnltk.data.path.append('/kaggle/working/nltk_data')\nnltk_data_path = \"/kaggle/working/nltk_data\"\nnltk.data.path.append(nltk_data_path)\nos.makedirs(nltk_data_path, exist_ok=True)\nnltk.download('wordnet', download_dir=nltk_data_path)\nnltk.download('omw-1.4', download_dir=nltk_data_path)\nshutil.move(os.path.join(nltk_data_path, \"corpora/wordnet.zip\"), \"/kaggle/working/wordnet.zip\")\nshutil.move(os.path.join(nltk_data_path, \"corpora/omw-1.4.zip\"), \"/kaggle/working/omw-1.4.zip\")\nwith zipfile.ZipFile(\"/kaggle/working/wordnet.zip\", 'r') as zip_ref:\n    zip_ref.extractall(nltk_data_path + \"/corpora\")\n\nwith zipfile.ZipFile(\"/kaggle/working/omw-1.4.zip\", 'r') as zip_ref:\n    zip_ref.extractall(nltk_data_path + \"/corpora\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:07:28.556708Z","iopub.execute_input":"2025-03-06T09:07:28.556962Z","iopub.status.idle":"2025-03-06T09:07:30.786258Z","shell.execute_reply.started":"2025-03-06T09:07:28.556942Z","shell.execute_reply":"2025-03-06T09:07:30.785320Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to\n[nltk_data]     /kaggle/working/nltk_data...\n[nltk_data] Downloading package omw-1.4 to\n[nltk_data]     /kaggle/working/nltk_data...\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /kaggle/working/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to\n[nltk_data]     /kaggle/working/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import XLMRobertaTokenizer, TFXLMRobertaForSequenceClassification\ndef augment_text(df, augmenter, repetitions=1):\n    aug_texts = []\n    for _, row in df.iterrows():\n        text = row['Img-Text']\n        for _ in range(repetitions):\n            augmented_text = augmenter.augment(text)\n            aug_texts.append((augmented_text, row['Text-Label']))\n    return pd.DataFrame(aug_texts, columns=['Img-Text', 'Text-Label'])\naugmenter = naw.SynonymAug(aug_src='wordnet')\nmax_size = df['Text-Label'].value_counts().max()\ndf_balanced = pd.DataFrame()\nfor label in df['Text-Label'].unique():\n    df_class = df[df['Text-Label'] == label]\n    df_class_aug = augment_text(df_class, augmenter, repetitions=max_size // len(df_class) - 1)\n    df_balanced = pd.concat([df_balanced, df_class, df_class_aug])\ndf_balanced.reset_index(drop=True, inplace=True)\ndf_balanced = df_balanced.sample(frac=1, random_state=123).reset_index(drop=True)\nclass_names = ['0', '1']\n\ntokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n\ndef encode_texts(tokenizer, texts, max_length=256):\n    input_ids = []\n    attention_masks = []\n\n    for text in texts:\n        text = str(text)\n        encoded = tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=max_length,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='tf',\n        )\n\n        input_ids.append(encoded['input_ids'][0])\n        attention_masks.append(encoded['attention_mask'][0])\n\n    return tf.convert_to_tensor(input_ids), tf.convert_to_tensor(attention_masks)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:07:30.787153Z","iopub.execute_input":"2025-03-06T09:07:30.787553Z","iopub.status.idle":"2025-03-06T09:07:41.521150Z","shell.execute_reply.started":"2025-03-06T09:07:30.787522Z","shell.execute_reply":"2025-03-06T09:07:41.520183Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-29d39a0d183a>:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  df_balanced = pd.concat([df_balanced, df_class, df_class_aug])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b85ab30e8414c45a1228cd0d550ebdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deaa01b18b5b4b02aae458a51da7a8b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65028966c1e64be786116b7f7b4d20f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"977abf355a0845fab315e8b51c3a7e54"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"X_train, X_temp, y_train, y_temp = train_test_split(df_balanced['Img-Text'], df_balanced['Text-Label'], test_size=0.2, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\ntrain_inputs, train_masks = encode_texts(tokenizer, X_train)\nval_inputs, val_masks = encode_texts(tokenizer, X_val)\ntest_inputs, test_masks = encode_texts(tokenizer, X_test)\ntrain_labels = tf.convert_to_tensor(y_train.to_numpy().astype('int32'))\nval_labels = tf.convert_to_tensor(y_val.to_numpy().astype('int32'))\ntest_labels = tf.convert_to_tensor(y_test.to_numpy().astype('int32'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:07:41.522074Z","iopub.execute_input":"2025-03-06T09:07:41.522336Z","iopub.status.idle":"2025-03-06T09:07:50.072746Z","shell.execute_reply.started":"2025-03-06T09:07:41.522281Z","shell.execute_reply":"2025-03-06T09:07:50.072050Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = TFXLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=len(class_names))\noptimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nmodel.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\nbatch_size = 20\nhistory = model.fit(\n    [train_inputs, train_masks],\n    train_labels,\n    batch_size=batch_size,\n    validation_data=([val_inputs, val_masks], val_labels), \n    epochs=20,\n    callbacks=[early_stopping]\n)\nprint(\"Training Loss per Epoch:\", history.history['loss'])\nprint(\"Training Accuracy per Epoch:\", history.history['accuracy'])\nprint(\"Validation Loss per Epoch:\", history.history['val_loss'])\nprint(\"Validation Accuracy per Epoch:\", history.history['val_accuracy'])\ntest_loss, test_accuracy = model.evaluate([test_inputs, test_masks], test_labels)\nprint(\"Test Loss:\", test_loss)\nprint(\"Test Accuracy:\", test_accuracy)\nmodel.save('/kaggle/working/xlm_roberta_model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T09:07:50.074508Z","iopub.execute_input":"2025-03-06T09:07:50.074724Z","iopub.status.idle":"2025-03-06T09:37:01.265742Z","shell.execute_reply.started":"2025-03-06T09:07:50.074706Z","shell.execute_reply":"2025-03-06T09:37:01.264419Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c4883e185b247f7aafbfb35ae876768"}},"metadata":{}},{"name":"stderr","text":"All PyTorch model weights were used when initializing TFXLMRobertaForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFXLMRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n287/287 [==============================] - 369s 1s/step - loss: 0.4620 - accuracy: 0.7713 - val_loss: 0.4151 - val_accuracy: 0.7919\nEpoch 2/20\n287/287 [==============================] - 331s 1s/step - loss: 0.4006 - accuracy: 0.7970 - val_loss: 0.3771 - val_accuracy: 0.8128\nEpoch 3/20\n287/287 [==============================] - 331s 1s/step - loss: 0.3712 - accuracy: 0.8193 - val_loss: 0.4163 - val_accuracy: 0.8059\nEpoch 4/20\n287/287 [==============================] - 331s 1s/step - loss: 0.3213 - accuracy: 0.8467 - val_loss: 0.4025 - val_accuracy: 0.8282\nEpoch 5/20\n287/287 [==============================] - 331s 1s/step - loss: 0.2774 - accuracy: 0.8703 - val_loss: 0.4981 - val_accuracy: 0.8268\nTraining Loss per Epoch: [0.46199527382850647, 0.40059900283813477, 0.37116095423698425, 0.3212928771972656, 0.2774168848991394]\nTraining Accuracy per Epoch: [0.7713388204574585, 0.7969977259635925, 0.819340169429779, 0.8467446565628052, 0.8703089356422424]\nValidation Loss per Epoch: [0.415134459733963, 0.3770792484283447, 0.4163353443145752, 0.4024604558944702, 0.4981417953968048]\nValidation Accuracy per Epoch: [0.7918994426727295, 0.8128491640090942, 0.8058659434318542, 0.8282122611999512, 0.826815664768219]\n23/23 [==============================] - 13s 570ms/step - loss: 0.5676 - accuracy: 0.7992\nTest Loss: 0.5675938129425049\nTest Accuracy: 0.7991631627082825\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-034af0deae25>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/xlm_roberta_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xlm_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"],"ename":"NameError","evalue":"name 'torch' is not defined","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"model.save_pretrained('/kaggle/working/xlm_roberta_model')\n!zip -r /kaggle/working/xlm_roberta_model.zip /kaggle/working/xlm_roberta_model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Vision transformer fine tuning","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow transformers scikit-learn matplotlib seaborn pandas numpy tqdm\n!pip install --upgrade torch torchvision transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T17:01:34.602707Z","iopub.execute_input":"2025-03-06T17:01:34.602994Z","iopub.status.idle":"2025-03-06T17:04:31.208747Z","shell.execute_reply.started":"2025-03-06T17:01:34.602972Z","shell.execute_reply":"2025-03-06T17:04:31.207667Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.12.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nCollecting torch\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nCollecting torchvision\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting transformers\n  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.2.0 (from torch)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, transformers, torchvision\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu121\n    Uninstalling torchvision-0.20.1+cu121:\n      Successfully uninstalled torchvision-0.20.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.6.0 torchvision-0.21.0 transformers-4.49.0 triton-3.2.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import ViTForImageClassification, ViTConfig\nfrom torch.optim.lr_scheduler import StepLR\nfrom sklearn.preprocessing import LabelEncoder\nfrom PIL import Image, UnidentifiedImageError\nimport os\nimport glob\nimport random\nfrom tqdm import tqdm ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T17:30:15.809774Z","iopub.execute_input":"2025-03-06T17:30:15.810166Z","iopub.status.idle":"2025-03-06T17:30:34.242822Z","shell.execute_reply.started":"2025-03-06T17:30:15.810136Z","shell.execute_reply":"2025-03-06T17:30:34.242161Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclass CustomDataset(Dataset):\n    def __init__(self, csv_path, img_dir, transform=None):\n        self.data = pd.read_csv(csv_path)\n        self.data = self.data.dropna(subset=[\"Img-Name\"]).reset_index(drop=True)\n        self.data[\"Img-Name\"] = self.data[\"Img-Name\"].astype(str)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.label_encoder = LabelEncoder()\n        self.data[\"Img-Label\"] = self.label_encoder.fit_transform(self.data[\"Img-Label\"])\n        self.valid_indices = self._filter_valid_images()\n\n    def _find_correct_image_path(self, img_name):\n        base_name = os.path.splitext(img_name)[0]  \n        possible_files = glob.glob(os.path.join(self.img_dir, f\"{base_name}.*\"))  \n        \n        for file in possible_files:\n            if file.lower().endswith(('.jpg', '.jpeg', '.png')): \n                return file\n        return None  \n\n    def _filter_valid_images(self):\n        valid_indices = []\n        for idx in range(len(self.data)):\n            img_name = self.data.iloc[idx, 0]\n            img_path = self._find_correct_image_path(img_name)\n            \n            if img_path:\n                try:\n                    with Image.open(img_path) as img:\n                        img.verify()  \n                    valid_indices.append(idx)\n                except (UnidentifiedImageError, OSError):\n                    print(f\"Skipping corrupt image: {img_path}\")\n        return valid_indices\n\n    def __len__(self):\n        return len(self.valid_indices)\n\n    def __getitem__(self, idx):\n        valid_idx = self.valid_indices[idx]\n        img_name = self.data.iloc[valid_idx, 0]\n        img_path = self._find_correct_image_path(img_name)\n        if not img_path:\n            random_idx = random.choice(self.valid_indices)\n            img_name = self.data.iloc[random_idx, 0]\n            img_path = self._find_correct_image_path(img_name)\n        label = self.data.iloc[valid_idx, 3]  \n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n        except (UnidentifiedImageError, OSError):\n            print(f\"Skipping unreadable image: {img_path}\")\n            random_idx = random.choice(self.valid_indices)\n            random_img_name = self.data.iloc[random_idx, 0]\n            random_img_path = self._find_correct_image_path(random_img_name)\n            image = Image.open(random_img_path).convert(\"RGB\")\n            label = self.data.iloc[random_idx, 3]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, torch.tensor(label, dtype=torch.long)\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T15:06:36.100994Z","iopub.execute_input":"2025-03-06T15:06:36.101334Z","iopub.status.idle":"2025-03-06T15:06:36.112538Z","shell.execute_reply.started":"2025-03-06T15:06:36.101307Z","shell.execute_reply":"2025-03-06T15:06:36.111551Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"csv_file = \"/kaggle/input/multibully/Cyberbully_corrected_emotion_sentiment.xlsx - cyberbully.csv\"  # Change to your CSV file path\nimg_directory = \"/kaggle/input/multibully/bully_data/bully_data\"  \ndataset = CustomDataset(csv_file, img_directory, transform=transform)\nnum_classes = 2  \ntrain_size = int(0.8 * len(dataset))\nvalid_size = len(dataset) - train_size\ntrain_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\nconfig = ViTConfig.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=num_classes)\nmodel = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", config=config)\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=5e-5)\nscheduler = StepLR(optimizer, step_size=1, gamma=0.9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T15:29:42.951344Z","iopub.execute_input":"2025-03-06T15:29:42.951630Z","iopub.status.idle":"2025-03-06T15:30:15.897372Z","shell.execute_reply.started":"2025-03-06T15:29:42.951608Z","shell.execute_reply":"2025-03-06T15:30:15.896196Z"}},"outputs":[{"name":"stdout","text":"Skipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/411.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/2655.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/2663.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/2665.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/2705.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/2707.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/2723.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/2795.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/2874.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/3010.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/4150.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5179.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5181.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5187.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5189.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5303.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5315.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5317.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5325.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5447.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5491.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5493.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5495.jpg\nSkipping corrupt image: /kaggle/input/multibully/bully_data/bully_data/5583.jpg\n","output_type":"stream"},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-107a9c5807bf>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mViTConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/vit-base-patch16-224-in21k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mViTForImageClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"google/vit-base-patch16-224-in21k\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3162\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3163\u001b[0m                 )\n\u001b[0;32m-> 3164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     )\n\u001b[0;32m-> 1326\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1327\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}],"execution_count":17},{"cell_type":"code","source":"def train(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    correct_predictions = 0\n    total_samples = 0\n\n    for inputs, labels in tqdm(loader, desc=\"Training\"):\n        inputs, labels = inputs.to(device), labels.to(device)  # Move to GPU/CPU\n\n        optimizer.zero_grad()\n        outputs = model(inputs).logits  # Extract logits\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct_predictions += (predicted == labels).sum().item()\n        total_samples += len(labels)\n\n    avg_loss = total_loss / len(loader)\n    accuracy = correct_predictions / total_samples\n    return avg_loss, accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T15:09:42.789624Z","iopub.execute_input":"2025-03-06T15:09:42.790061Z","iopub.status.idle":"2025-03-06T15:09:42.797750Z","shell.execute_reply.started":"2025-03-06T15:09:42.790020Z","shell.execute_reply":"2025-03-06T15:09:42.796706Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct_predictions = 0\n    total_samples = 0\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(loader, desc=\"Evaluating\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs).logits\n            loss = criterion(outputs, labels)\n\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct_predictions += (predicted == labels).sum().item()\n            total_samples += len(labels)\n\n    avg_loss = total_loss / len(loader)\n    accuracy = correct_predictions / total_samples\n    return avg_loss, accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T15:09:46.344658Z","iopub.execute_input":"2025-03-06T15:09:46.345033Z","iopub.status.idle":"2025-03-06T15:09:46.350613Z","shell.execute_reply.started":"2025-03-06T15:09:46.344981Z","shell.execute_reply":"2025-03-06T15:09:46.349601Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"num_epochs = 20\nearly_stop_patience = 3\nbest_valid_loss = float(\"inf\")\nepochs_since_improvement = 0\ninputs, labels = inputs.to(device), labels.to(device)\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch+1}/{num_epochs}\")\n    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, device)\n    valid_loss, valid_accuracy = evaluate(model, valid_loader, criterion, device)\n\n    print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n    print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.4f}\")\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        epochs_since_improvement = 0\n    else:\n        epochs_since_improvement += 1\n\n    if epochs_since_improvement == early_stop_patience:\n        print(\"Early stopping triggered\")\n        break\n    scheduler.step()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-06T15:11:30.624805Z","iopub.execute_input":"2025-03-06T15:11:30.625202Z","iopub.status.idle":"2025-03-06T15:11:30.648743Z","shell.execute_reply.started":"2025-03-06T15:11:30.625167Z","shell.execute_reply":"2025-03-06T15:11:30.647631Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-948483f0e324>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepochs_since_improvement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"],"ename":"NameError","evalue":"name 'inputs' is not defined","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"model.save('/kaggle/working/vit_model')\ntorch.save(model.state_dict(), '/kaggle/working/vit_model_dict.pth')\nmodel_save_path = \"/kaggle/working/vit_model.pth\"\ntorch.save(model, model_save_path)  \nprint(f\"Model saved to {model_save_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Final Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\nimport pandas as pd\nimport numpy as np\nimport os\nimport pickle\nimport random\nfrom PIL import Image, ImageOps, UnidentifiedImageError\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nfrom transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, ViTImageProcessor\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\ncsv_path = '/kaggle/input/multibully/Cyberbully_corrected_emotion_sentiment.xlsx - cyberbully.csv'\nimage_dir = '/kaggle/input/multibully/bullydata/bullydata'  \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nroberta_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\ntext_model = XLMRobertaForSequenceClassification.from_pretrained(\"/kaggle/input/checkpoint/roberta_model1/kaggle/working/roberta_model1\",from_tf=True)\ntext_model = text_model.to(device)\ntext_model.eval()\n\nvit_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\nvit_model = torch.load('/kaggle/input/checkpoint/vit_model.pth', map_location=device)\nvit_model = vit_model.to(device)\nvit_model.eval()\n\nclass TextAugmentation:\n    def __init__(self, p=0.15):  \n        self.p = p\n    def augment(self, text):\n        if random.random() > self.p:\n            return text\n        words = text.split()\n        if len(words) <= 3:\n            return text\n        if len(words) > 3:\n            del_idx = random.randint(0, len(words) - 1)\n            words.pop(del_idx)\n            \n        return ' '.join(words)\n\nclass ImageAugmentation:\n    def __init__(self):\n        self.transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.2),  \n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n        ])\n        \n        self.basic_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n        ])\n    \n    def augment(self, image, is_training=True):\n        if is_training:\n            return self.transform(image)\n        return self.basic_transform(image)\n\ndef extract_text_features(text):\n    inputs = roberta_tokenizer(\n        text, add_special_tokens=True, max_length=512,\n        padding='max_length', truncation=True, return_tensors=\"pt\"\n    ).to(device)\n    with torch.no_grad():\n        outputs = text_model(**inputs, output_hidden_states=True)\n        hidden_states = outputs.hidden_states[-1]\n        feature_vector = hidden_states[:, 0, :]\n    \n    noise = np.random.normal(0, 0.05, feature_vector.shape)\n    feature_vector = feature_vector.cpu().numpy() + noise\n    return feature_vector.squeeze(0)\n\ndef extract_image_features(image_path, augment=False):\n    img_aug = ImageAugmentation()\n    try:\n        image = Image.open(image_path).convert('RGB')\n        if augment:\n            img_tensor = img_aug.augment(image, is_training=True).unsqueeze(0).to(device)\n        else:\n            img_tensor = img_aug.augment(image, is_training=False).unsqueeze(0).to(device)\n            \n        with torch.no_grad():\n            outputs = vit_model(img_tensor)\n        feature_vector = outputs.squeeze(0).cpu().numpy()\n        noise = np.random.normal(0, 0.05, feature_vector.shape)\n        return feature_vector + noise\n    except (FileNotFoundError, UnidentifiedImageError, OSError) as e:\n        print(f\"Skipping image {image_path}: {e}\")\n        return np.zeros(768)\n\ndef extract_metadata_features(row):\n    features = []\n    sentiment_map = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n    sentiment = sentiment_map.get(row.get('Sentiment', 'Neutral'), 0)\n    features.append(sentiment)\n    emotions = ['Disgust', 'Surprise', 'Happiness', 'Angry', 'Fear'] \n    emotion = row.get('Emotion', 'Neutral')\n    emotion_vec = [1 if emotion == e else 0 for e in emotions]\n    features.extend(emotion_vec)\n    sarcasm = 1 if row.get('Sarcasm', 'No') == 'Yes' else 0\n    features.append(sarcasm)\n    noise = np.random.normal(0, 0.1, len(features))\n    features = np.array(features, dtype=np.float32) + noise\n    return features\n\ndef save_text_features(csv_path, save_path):\n    df = pd.read_csv(csv_path).dropna(subset=['Img-Text-Label'])\n    text_feats = {}\n    for i, row in df.iterrows():\n        text = row['Img-Text']\n        text_feats[text] = extract_text_features(text)\n        if i % 100 == 0:\n            print(f\"Processed {i}/{len(df)} text samples\")\n    with open(save_path, 'wb') as f:\n        pickle.dump(text_feats, f)\n    print(f\"Text features saved to {save_path}\")\n\ndef save_image_features(csv_path, image_dir, save_path):\n    df = pd.read_csv(csv_path).dropna(subset=['Img-Text-Label'])\n    image_feats = {}\n    for i, row in enumerate(df['Img-Name'].tolist()):\n        img_path = os.path.join(image_dir, row)\n        image_feats[row] = extract_image_features(img_path) if os.path.exists(img_path) else np.zeros(768)\n        if i % 100 == 0:\n            print(f\"Processed {i}/{len(df)} image samples\")\n    np.save(save_path, image_feats)\n    print(f\"Image features saved to {save_path}\")\n\ndef save_metadata_features(csv_path, save_path):\n    df = pd.read_csv(csv_path).dropna(subset=['Img-Text-Label'])\n    metadata_feats = {}\n    for i, row in df.iterrows():\n        img_name = row['Img-Name']\n        metadata_feats[img_name] = extract_metadata_features(row)\n        if i % 100 == 0:\n            print(f\"Processed {i}/{len(df)} metadata samples\")\n    with open(save_path, 'wb') as f:\n        pickle.dump(metadata_feats, f)\n    print(f\"Metadata features saved to {save_path}\")\n\nclass CyberbullyingDataset(Dataset):\n    def __init__(self, dataframe, text_feat_path, img_feat_path, metadata_feat_path, label_map, \n                 augment=False, text_augmentor=None):\n        self.data = dataframe\n        self.label_map = label_map\n        self.augment = augment\n        self.text_augmentor = text_augmentor if text_augmentor and augment else None\n        with open(text_feat_path, 'rb') as f:\n            self.text_feats = pickle.load(f)\n        self.image_feats = np.load(img_feat_path, allow_pickle=True).item()\n        \n        with open(metadata_feat_path, 'rb') as f:\n            self.metadata_feats = pickle.load(f)\n\n        self.texts = self.data['Img-Text'].tolist()\n        self.labels = [label_map[label] for label in self.data['Img-Text-Label'].tolist()]\n        self.image_names = self.data['Img-Name'].tolist()\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        img_name = self.image_names[idx]\n        label = self.labels[idx]\n        text_feat = self.text_feats.get(text, np.zeros(768))\n        img_feat = self.image_feats.get(img_name, np.zeros(768))\n        meta_feat = self.metadata_feats.get(img_name, np.zeros(7))  \n        return (\n            torch.tensor(text_feat, dtype=torch.float32),\n            torch.tensor(img_feat, dtype=torch.float32),\n            torch.tensor(meta_feat, dtype=torch.float32),\n            torch.tensor(label, dtype=torch.long)\n        )\n\nclass GatedFusion(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.text_gate = nn.Linear(dim, dim)\n        self.image_gate = nn.Linear(dim, dim)\n        self.fusion_gate = nn.Linear(dim * 2, 1)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, text_feats, image_feats):\n        text_gate = self.sigmoid(self.text_gate(text_feats))\n        image_gate = self.sigmoid(self.image_gate(image_feats))\n        gated_text = text_feats * text_gate\n        gated_image = image_feats * image_gate\n        combined = torch.cat([text_feats, image_feats], dim=1)\n        fusion_weight = self.sigmoid(self.fusion_gate(combined))\n        fusion = fusion_weight * gated_text + (1 - fusion_weight) * gated_image\n        return fusion\n\nclass CyberbullyingClassifier(nn.Module):\n    def __init__(self, text_dim=768, img_dim=768, meta_dim=7):  \n        super().__init__()\n        self.feature_dim = text_dim\n        self.fusion = GatedFusion(text_dim)\n        self.meta_encoder = nn.Sequential(\n            nn.Linear(meta_dim, 32),  \n            nn.ReLU()\n        )\n        self.fc1 = nn.Linear(text_dim, 256)  \n        self.fc2 = nn.Linear(256 + 32, 128)  \n        self.classifier = nn.Linear(128, 2)\n        self.dropout1 = nn.Dropout(0.1)  \n        self.dropout2 = nn.Dropout(0.1)  \n        self.relu = nn.ReLU()\n\n    def forward(self, text_feats, image_feats, meta_feats):\n        meta_encoded = self.meta_encoder(meta_feats)\n        fused_features = self.fusion(text_feats, image_feats)\n        x = self.relu(self.fc1(fused_features))\n        x = self.dropout1(x)\n        x = torch.cat([x, meta_encoded], dim=1)\n        x = self.relu(self.fc2(x))\n        x = self.dropout2(x)\n        logits = self.classifier(x)\n        return logits\n\ndef train_and_evaluate(csv_path, text_feat_path, img_feat_path, metadata_feat_path, \n                       batch_size=32, epochs=100, lr=0.001, test_size=0.2):  # Fewer epochs, higher lr\n    if torch.cuda.is_available():\n        torch.multiprocessing.set_start_method('spawn', force=True)\n    df = pd.read_csv(csv_path).dropna(subset=['Img-Text-Label'])\n    df = df[df['Img-Text-Label'].isin(['Bully', 'Nonbully'])]\n    \n    label_map = {\"Bully\": 1, \"Nonbully\": 0}\n    text_augmentor = TextAugmentation(p=0.15)  \n    train_df, test_df = train_test_split(\n        df, test_size=test_size, random_state=42, \n        stratify=df['Img-Text-Label']\n    )\n    print(f\"Training samples: {len(train_df)}, Test samples: {len(test_df)}\")\n    print(f\"Training class distribution: {train_df['Img-Text-Label'].value_counts()}\")\n    print(f\"Test class distribution: {test_df['Img-Text-Label'].value_counts()}\")\n    train_dataset = CyberbullyingDataset(\n        train_df, text_feat_path, img_feat_path, metadata_feat_path, \n        label_map, augment=False, text_augmentor=None\n    )\n    \n    test_dataset = CyberbullyingDataset(\n        test_df, text_feat_path, img_feat_path, metadata_feat_path, \n        label_map, augment=False\n    )\n    \n    train_loader = DataLoader(\n        train_dataset, batch_size=batch_size, shuffle=True, \n        num_workers=0\n    )\n    \n    test_loader = DataLoader(\n        test_dataset, batch_size=batch_size, shuffle=False, \n        num_workers=0\n    )\n    \n    with open(metadata_feat_path, 'rb') as f:\n        metadata_feats = pickle.load(f)\n        sample_key = list(metadata_feats.keys())[0]\n        meta_dim = metadata_feats[sample_key].shape[0]\n        print(f\"Using metadata dimension: {meta_dim}\")\n    \n    model = CyberbullyingClassifier(meta_dim=meta_dim).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.7, patience=2, verbose=True\n    )\n    best_accuracy = 0\n    patience = 10\n    trigger_times = 0\n    for epoch in range(epochs):\n        model.train()\n        train_loss, train_correct, train_total = 0, 0, 0\n        for text_feats, image_feats, meta_feats, labels in train_loader:\n            text_feats = text_feats.to(device)\n            image_feats = image_feats.to(device)\n            meta_feats = meta_feats.to(device)\n            labels = labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(text_feats, image_feats, meta_feats)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            train_loss += loss.item() * labels.size(0)\n            train_correct += (outputs.argmax(1) == labels).sum().item()\n            train_total += labels.size(0)\n        \n        train_loss = train_loss / train_total\n        train_accuracy = train_correct / train_total\n        model.eval()\n        test_loss, test_correct, test_total = 0, 0, 0\n        test_preds, test_true = [], []\n        with torch.no_grad():\n            for text_feats, image_feats, meta_feats, labels in test_loader:\n                text_feats = text_feats.to(device)\n                image_feats = image_feats.to(device)\n                meta_feats = meta_feats.to(device)\n                labels = labels.to(device)\n                \n                outputs = model(text_feats, image_feats, meta_feats)\n                loss = criterion(outputs, labels)\n                \n                test_loss += loss.item() * labels.size(0)\n                test_preds.extend(outputs.argmax(1).cpu().numpy())\n                test_true.extend(labels.cpu().numpy())\n                test_correct += (outputs.argmax(1) == labels).sum().item()\n                test_total += labels.size(0)\n        \n        test_loss = test_loss / test_total\n        test_accuracy = test_correct / test_total\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n        print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.4f}\")\n        scheduler.step(test_accuracy)\n        if test_accuracy > best_accuracy:\n            best_accuracy = test_accuracy\n            trigger_times = 0\n            torch.save(model.state_dict(), \"cyberbullying_model_best.pth\")\n            print(f\"Model saved with test accuracy: {test_accuracy:.4f}\")\n            \n        else:\n            trigger_times += 1\n            if trigger_times >= patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n    model.load_state_dict(torch.load(\"cyberbullying_model_best.pth\"))\n    model.eval()\n    test_correct, test_total = 0, 0\n    test_preds, test_true = [], []\n    \n    with torch.no_grad():\n        for text_feats, image_feats, meta_feats, labels in test_loader:\n            text_feats = text_feats.to(device)\n            image_feats = image_feats.to(device)\n            meta_feats = meta_feats.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(text_feats, image_feats, meta_feats)\n            \n            test_preds.extend(outputs.argmax(1).cpu().numpy())\n            test_true.extend(labels.cpu().numpy())\n            test_correct += (outputs.argmax(1) == labels).sum().item()\n            test_total += labels.size(0)\n    \n    final_accuracy = test_correct / test_total\n    print(\"\\nFinal Test Results:\")\n    print(f\"Accuracy: {final_accuracy:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(test_true, test_preds, target_names=['Nonbully', 'Bully']))\n    print(\"\\nConfusion Matrix:\")\n    cm = confusion_matrix(test_true, test_preds)\n    print(cm)\n    return model\ndef train_and_evaluate_kfold(csv_path, text_feat_path, img_feat_path, metadata_feat_path, \n                         batch_size=32, epochs=100, lr=0.001, n_splits=5):\n    if torch.cuda.is_available():\n        torch.multiprocessing.set_start_method('spawn', force=True)\n    df = pd.read_csv(csv_path).dropna(subset=['Img-Text-Label'])\n    df = df[df['Img-Text-Label'].isin(['Bully', 'Nonbully'])]\n    label_map = {\"Bully\": 1, \"Nonbully\": 0}\n    text_augmentor = TextAugmentation(p=0.15)\n    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n    fold_accuracies = []\n    fold_reports = []\n    fold_cms = []\n    full_dataset = df.reset_index(drop=True)\n    with open(metadata_feat_path, 'rb') as f:\n        metadata_feats = pickle.load(f)\n        sample_key = list(metadata_feats.keys())[0]\n        meta_dim = metadata_feats[sample_key].shape[0]\n        print(f\"Detected metadata feature dimension: {meta_dim}\")\n    for fold, (train_idx, test_idx) in enumerate(kf.split(full_dataset)):\n        print(f\"\\n{'='*50}\")\n        print(f\"FOLD {fold+1}/{n_splits}\")\n        print(f\"{'='*50}\")\n        train_df = full_dataset.iloc[train_idx]\n        test_df = full_dataset.iloc[test_idx]\n        print(f\"Training samples: {len(train_df)}, Test samples: {len(test_df)}\")\n        print(f\"Training class distribution: {train_df['Img-Text-Label'].value_counts()}\")\n        print(f\"Test class distribution: {test_df['Img-Text-Label'].value_counts()}\")\n        train_dataset = CyberbullyingDataset(\n            train_df, text_feat_path, img_feat_path, metadata_feat_path, \n            label_map, augment=False, text_augmentor=None\n        )\n        \n        test_dataset = CyberbullyingDataset(\n            test_df, text_feat_path, img_feat_path, metadata_feat_path, \n            label_map, augment=False\n        )\n        train_loader = DataLoader(\n            train_dataset, batch_size=batch_size, shuffle=True, \n            num_workers=0\n        )\n        \n        test_loader = DataLoader(\n            test_dataset, batch_size=batch_size, shuffle=False, \n            num_workers=0\n        )\n        model = CyberbullyingClassifier(meta_dim=meta_dim).to(device)\n        criterion = nn.CrossEntropyLoss()\n        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='max', factor=0.7, patience=2, verbose=True\n        )\n        best_accuracy = 0\n        patience = 10\n        trigger_times = 0\n        for epoch in range(epochs):\n            model.train()\n            train_loss, train_correct, train_total = 0, 0, 0\n            \n            for text_feats, image_feats, meta_feats, labels in train_loader:\n                text_feats = text_feats.to(device)\n                image_feats = image_feats.to(device)\n                meta_feats = meta_feats.to(device)\n                labels = labels.to(device)\n                \n                optimizer.zero_grad()\n                outputs = model(text_feats, image_feats, meta_feats)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                optimizer.step()\n                train_loss += loss.item() * labels.size(0)\n                train_correct += (outputs.argmax(1) == labels).sum().item()\n                train_total += labels.size(0)\n            \n            train_loss = train_loss / train_total\n            train_accuracy = train_correct / train_total\n            model.eval()\n            test_loss, test_correct, test_total = 0, 0, 0\n            test_preds, test_true = [], []\n            \n            with torch.no_grad():\n                for text_feats, image_feats, meta_feats, labels in test_loader:\n                    text_feats = text_feats.to(device)\n                    image_feats = image_feats.to(device)\n                    meta_feats = meta_feats.to(device)\n                    labels = labels.to(device)\n                    \n                    outputs = model(text_feats, image_feats, meta_feats)\n                    loss = criterion(outputs, labels)\n                    \n                    test_loss += loss.item() * labels.size(0)\n                    test_preds.extend(outputs.argmax(1).cpu().numpy())\n                    test_true.extend(labels.cpu().numpy())\n                    test_correct += (outputs.argmax(1) == labels).sum().item()\n                    test_total += labels.size(0)\n            \n            test_loss = test_loss / test_total\n            test_accuracy = test_correct / test_total\n            print(f\"Epoch {epoch+1}/{epochs}\")\n            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n            print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.4f}\")\n            scheduler.step(test_accuracy)\n            if test_accuracy > best_accuracy:\n                best_accuracy = test_accuracy\n                trigger_times = 0\n                torch.save(model.state_dict(), f\"cyberbullying_model_fold{fold+1}_best.pth\")\n                print(f\"Model saved with test accuracy: {test_accuracy:.4f}\")\n                \n            else:\n                trigger_times += 1\n                if trigger_times >= patience:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n        model.load_state_dict(torch.load(f\"cyberbullying_model_fold{fold+1}_best.pth\"))\n        model.eval()\n        test_correct, test_total = 0, 0\n        test_preds, test_true = [], []\n        \n        with torch.no_grad():\n            for text_feats, image_feats, meta_feats, labels in test_loader:\n                text_feats = text_feats.to(device)\n                image_feats = image_feats.to(device)\n                meta_feats = meta_feats.to(device)\n                labels = labels.to(device)\n                \n                outputs = model(text_feats, image_feats, meta_feats)\n                \n                test_preds.extend(outputs.argmax(1).cpu().numpy())\n                test_true.extend(labels.cpu().numpy())\n                test_correct += (outputs.argmax(1) == labels).sum().item()\n                test_total += labels.size(0)\n        \n        fold_accuracy = test_correct / test_total\n        fold_accuracies.append(fold_accuracy)\n        fold_report = classification_report(test_true, test_preds, target_names=['Nonbully', 'Bully'], output_dict=True)\n        fold_reports.append(fold_report)\n        fold_cm = confusion_matrix(test_true, test_preds)\n        fold_cms.append(fold_cm)\n        \n        print(f\"\\nFold {fold+1} Results:\")\n        print(f\"Accuracy: {fold_accuracy:.4f}\")\n        print(\"\\nClassification Report:\")\n        print(classification_report(test_true, test_preds, target_names=['Nonbully', 'Bully']))\n        \n        print(\"\\nConfusion Matrix:\")\n        print(fold_cm)\n    avg_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n    print(f\"\\n{'='*50}\")\n    print(f\"AVERAGE RESULTS ACROSS {n_splits} FOLDS\")\n    print(f\"{'='*50}\")\n    print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n    avg_report = {}\n    for label in ['Nonbully', 'Bully']:\n        avg_report[label] = {\n            'precision': sum(report[label]['precision'] for report in fold_reports) / n_splits,\n            'recall': sum(report[label]['recall'] for report in fold_reports) / n_splits,\n            'f1-score': sum(report[label]['f1-score'] for report in fold_reports) / n_splits\n        }\n    \n    avg_report['macro avg'] = {\n        'precision': sum(report['macro avg']['precision'] for report in fold_reports) / n_splits,\n        'recall': sum(report['macro avg']['recall'] for report in fold_reports) / n_splits,\n        'f1-score': sum(report['macro avg']['f1-score'] for report in fold_reports) / n_splits\n    }\n    \n    avg_report['weighted avg'] = {\n        'precision': sum(report['weighted avg']['precision'] for report in fold_reports) / n_splits,\n        'recall': sum(report['weighted avg']['recall'] for report in fold_reports) / n_splits,\n        'f1-score': sum(report['weighted avg']['f1-score'] for report in fold_reports) / n_splits\n    }\n    \n    print(\"\\nAverage Classification Report:\")\n    print(f\"               precision    recall  f1-score\")\n    print(f\"Nonbully       {avg_report['Nonbully']['precision']:.4f}      {avg_report['Nonbully']['recall']:.4f}    {avg_report['Nonbully']['f1-score']:.4f}\")\n    print(f\"Bully          {avg_report['Bully']['precision']:.4f}      {avg_report['Bully']['recall']:.4f}    {avg_report['Bully']['f1-score']:.4f}\")\n    print(f\"macro avg      {avg_report['macro avg']['precision']:.4f}      {avg_report['macro avg']['recall']:.4f}    {avg_report['macro avg']['f1-score']:.4f}\")\n    print(f\"weighted avg   {avg_report['weighted avg']['precision']:.4f}      {avg_report['weighted avg']['recall']:.4f}    {avg_report['weighted avg']['f1-score']:.4f}\")\n\n    avg_cm = np.mean(fold_cms, axis=0).astype(int)\n    print(\"\\nAverage Confusion Matrix:\")\n    print(avg_cm)\n    \n    return fold_accuracies, fold_reports, fold_cms\nif __name__ == \"__main__\":\n    text_feat_path = \"text_features.pkl\"\n    img_feat_path = \"image_features.npy\"\n    metadata_feat_path = \"metadata_features.pkl\"\n    if not os.path.exists(text_feat_path):\n        print(\"Extracting text features...\")\n        save_text_features(csv_path, text_feat_path)\n    \n    if not os.path.exists(img_feat_path):\n        print(\"Extracting image features...\")\n        save_image_features(csv_path, image_dir, img_feat_path)\n    \n    if not os.path.exists(metadata_feat_path):\n        print(\"Extracting metadata features...\")\n        save_metadata_features(csv_path, metadata_feat_path)\n    print(\"Starting K-fold cross-validation training...\")\n    fold_accuracies, fold_reports, fold_cms = train_and_evaluate_kfold(\n        csv_path=csv_path,\n        text_feat_path=text_feat_path,\n        img_feat_path=img_feat_path,\n        metadata_feat_path=metadata_feat_path,\n        batch_size=32,\n        epochs=100,\n        lr=0.001,\n        n_splits=5\n    )\n    print(\"\\nTraining final model on full dataset...\")\n    final_model = train_and_evaluate(\n        csv_path=csv_path,\n        text_feat_path=text_feat_path,\n        img_feat_path=img_feat_path,\n        metadata_feat_path=metadata_feat_path,\n        batch_size=32,\n        epochs=100,\n        lr=0.001\n    )\n    torch.save(final_model.state_dict(), \"cyberbullying_model_final.pth\")\n    print(\"Final model saved to cyberbullying_model_final.pth\")\n    print(\"Training and evaluation complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-01T17:54:42.415590Z","iopub.execute_input":"2025-05-01T17:54:42.415864Z","iopub.status.idle":"2025-05-01T17:59:51.508468Z","shell.execute_reply.started":"2025-05-01T17:54:42.415840Z","shell.execute_reply":"2025-05-01T17:59:51.507495Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"803beb11b87b4955a86437eaef7aab3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a6cc3e8373e4b5d9e2e56bddde35f17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c69c1adc83c44928df1440da96b9b80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dd0363e44c0420092104379a723b302"}},"metadata":{}},{"name":"stderr","text":"All TF 2.0 model weights were used when initializing XLMRobertaForSequenceClassification.\n\nAll the weights of XLMRobertaForSequenceClassification were initialized from the TF 2.0 model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27e20ce86d164e8db57d8dc8de69f867"}},"metadata":{}},{"name":"stderr","text":"<ipython-input-1-f083a802e9dc>:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  vit_model = torch.load('/kaggle/input/checkpoint/vit_model.pth', map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"Extracting text features...\nProcessed 0/5854 text samples\nProcessed 100/5854 text samples\nProcessed 200/5854 text samples\nProcessed 300/5854 text samples\nProcessed 400/5854 text samples\nProcessed 500/5854 text samples\nProcessed 600/5854 text samples\nProcessed 700/5854 text samples\nProcessed 800/5854 text samples\nProcessed 900/5854 text samples\nProcessed 1000/5854 text samples\nProcessed 1100/5854 text samples\nProcessed 1200/5854 text samples\nProcessed 1300/5854 text samples\nProcessed 1400/5854 text samples\nProcessed 1500/5854 text samples\nProcessed 1600/5854 text samples\nProcessed 1700/5854 text samples\nProcessed 1800/5854 text samples\nProcessed 1900/5854 text samples\nProcessed 2000/5854 text samples\nProcessed 2100/5854 text samples\nProcessed 2200/5854 text samples\nProcessed 2300/5854 text samples\nProcessed 2400/5854 text samples\nProcessed 2500/5854 text samples\nProcessed 2600/5854 text samples\nProcessed 2700/5854 text samples\nProcessed 2800/5854 text samples\nProcessed 2900/5854 text samples\nProcessed 3000/5854 text samples\nProcessed 3100/5854 text samples\nProcessed 3200/5854 text samples\nProcessed 3300/5854 text samples\nProcessed 3400/5854 text samples\nProcessed 3500/5854 text samples\nProcessed 3600/5854 text samples\nProcessed 3700/5854 text samples\nProcessed 3800/5854 text samples\nProcessed 3900/5854 text samples\nProcessed 4000/5854 text samples\nProcessed 4100/5854 text samples\nProcessed 4200/5854 text samples\nProcessed 4300/5854 text samples\nProcessed 4400/5854 text samples\nProcessed 4500/5854 text samples\nProcessed 4600/5854 text samples\nProcessed 4700/5854 text samples\nProcessed 4800/5854 text samples\nProcessed 4900/5854 text samples\nProcessed 5000/5854 text samples\nProcessed 5100/5854 text samples\nProcessed 5200/5854 text samples\nProcessed 5300/5854 text samples\nProcessed 5400/5854 text samples\nProcessed 5500/5854 text samples\nProcessed 5600/5854 text samples\nProcessed 5700/5854 text samples\nProcessed 5800/5854 text samples\nText features saved to text_features.pkl\nExtracting image features...\nProcessed 0/5854 image samples\nProcessed 100/5854 image samples\nProcessed 200/5854 image samples\nProcessed 300/5854 image samples\nProcessed 400/5854 image samples\nProcessed 500/5854 image samples\nProcessed 600/5854 image samples\nProcessed 700/5854 image samples\nProcessed 800/5854 image samples\nProcessed 900/5854 image samples\nProcessed 1000/5854 image samples\nProcessed 1100/5854 image samples\nProcessed 1200/5854 image samples\nProcessed 1300/5854 image samples\nProcessed 1400/5854 image samples\nProcessed 1500/5854 image samples\nProcessed 1600/5854 image samples\nProcessed 1700/5854 image samples\nProcessed 1800/5854 image samples\nProcessed 1900/5854 image samples\nProcessed 2000/5854 image samples\nProcessed 2100/5854 image samples\nProcessed 2200/5854 image samples\nProcessed 2300/5854 image samples\nProcessed 2400/5854 image samples\nProcessed 2500/5854 image samples\nProcessed 2600/5854 image samples\nProcessed 2700/5854 image samples\nProcessed 2800/5854 image samples\nProcessed 2900/5854 image samples\nProcessed 3000/5854 image samples\nProcessed 3100/5854 image samples\nProcessed 3200/5854 image samples\nProcessed 3300/5854 image samples\nProcessed 3400/5854 image samples\nProcessed 3500/5854 image samples\nProcessed 3600/5854 image samples\nProcessed 3700/5854 image samples\nProcessed 3800/5854 image samples\nProcessed 3900/5854 image samples\nProcessed 4000/5854 image samples\nProcessed 4100/5854 image samples\nProcessed 4200/5854 image samples\nProcessed 4300/5854 image samples\nProcessed 4400/5854 image samples\nProcessed 4500/5854 image samples\nProcessed 4600/5854 image samples\nProcessed 4700/5854 image samples\nProcessed 4800/5854 image samples\nProcessed 4900/5854 image samples\nProcessed 5000/5854 image samples\nProcessed 5100/5854 image samples\nProcessed 5200/5854 image samples\nProcessed 5300/5854 image samples\nProcessed 5400/5854 image samples\nProcessed 5500/5854 image samples\nProcessed 5600/5854 image samples\nProcessed 5700/5854 image samples\nProcessed 5800/5854 image samples\nImage features saved to image_features.npy\nExtracting metadata features...\nProcessed 0/5854 metadata samples\nProcessed 100/5854 metadata samples\nProcessed 200/5854 metadata samples\nProcessed 300/5854 metadata samples\nProcessed 400/5854 metadata samples\nProcessed 500/5854 metadata samples\nProcessed 600/5854 metadata samples\nProcessed 700/5854 metadata samples\nProcessed 800/5854 metadata samples\nProcessed 900/5854 metadata samples\nProcessed 1000/5854 metadata samples\nProcessed 1100/5854 metadata samples\nProcessed 1200/5854 metadata samples\nProcessed 1300/5854 metadata samples\nProcessed 1400/5854 metadata samples\nProcessed 1500/5854 metadata samples\nProcessed 1600/5854 metadata samples\nProcessed 1700/5854 metadata samples\nProcessed 1800/5854 metadata samples\nProcessed 1900/5854 metadata samples\nProcessed 2000/5854 metadata samples\nProcessed 2100/5854 metadata samples\nProcessed 2200/5854 metadata samples\nProcessed 2300/5854 metadata samples\nProcessed 2400/5854 metadata samples\nProcessed 2500/5854 metadata samples\nProcessed 2600/5854 metadata samples\nProcessed 2700/5854 metadata samples\nProcessed 2800/5854 metadata samples\nProcessed 2900/5854 metadata samples\nProcessed 3000/5854 metadata samples\nProcessed 3100/5854 metadata samples\nProcessed 3200/5854 metadata samples\nProcessed 3300/5854 metadata samples\nProcessed 3400/5854 metadata samples\nProcessed 3500/5854 metadata samples\nProcessed 3600/5854 metadata samples\nProcessed 3700/5854 metadata samples\nProcessed 3800/5854 metadata samples\nProcessed 3900/5854 metadata samples\nProcessed 4000/5854 metadata samples\nProcessed 4100/5854 metadata samples\nProcessed 4200/5854 metadata samples\nProcessed 4300/5854 metadata samples\nProcessed 4400/5854 metadata samples\nProcessed 4500/5854 metadata samples\nProcessed 4600/5854 metadata samples\nProcessed 4700/5854 metadata samples\nProcessed 4800/5854 metadata samples\nProcessed 4900/5854 metadata samples\nProcessed 5000/5854 metadata samples\nProcessed 5100/5854 metadata samples\nProcessed 5200/5854 metadata samples\nProcessed 5300/5854 metadata samples\nProcessed 5400/5854 metadata samples\nProcessed 5500/5854 metadata samples\nProcessed 5600/5854 metadata samples\nProcessed 5700/5854 metadata samples\nProcessed 5800/5854 metadata samples\nMetadata features saved to metadata_features.pkl\nStarting K-fold cross-validation training...\nDetected metadata feature dimension: 7\n\n==================================================\nFOLD 1/5\n==================================================\nTraining samples: 4683, Test samples: 1171\nTraining class distribution: Img-Text-Label\nBully       2551\nNonbully    2132\nName: count, dtype: int64\nTest class distribution: Img-Text-Label\nBully       671\nNonbully    500\nName: count, dtype: int64\nEpoch 1/100\nTrain Loss: 0.4754, Train Acc: 0.7813\nTest Loss: 0.3994, Test Acc: 0.8181\nModel saved with test accuracy: 0.8181\nEpoch 2/100\nTrain Loss: 0.4158, Train Acc: 0.8196\nTest Loss: 0.3850, Test Acc: 0.8207\nModel saved with test accuracy: 0.8207\nEpoch 3/100\nTrain Loss: 0.4074, Train Acc: 0.8253\nTest Loss: 0.3841, Test Acc: 0.8241\nModel saved with test accuracy: 0.8241\nEpoch 4/100\nTrain Loss: 0.4010, Train Acc: 0.8266\nTest Loss: 0.3875, Test Acc: 0.8215\nEpoch 5/100\nTrain Loss: 0.3982, Train Acc: 0.8298\nTest Loss: 0.3841, Test Acc: 0.8249\nModel saved with test accuracy: 0.8249\nEpoch 6/100\nTrain Loss: 0.3971, Train Acc: 0.8266\nTest Loss: 0.3869, Test Acc: 0.8301\nModel saved with test accuracy: 0.8301\nEpoch 7/100\nTrain Loss: 0.3947, Train Acc: 0.8313\nTest Loss: 0.3821, Test Acc: 0.8284\nEpoch 8/100\nTrain Loss: 0.3922, Train Acc: 0.8309\nTest Loss: 0.3972, Test Acc: 0.8258\nEpoch 9/100\nTrain Loss: 0.3907, Train Acc: 0.8322\nTest Loss: 0.3996, Test Acc: 0.8249\nEpoch 10/100\nTrain Loss: 0.3823, Train Acc: 0.8300\nTest Loss: 0.3931, Test Acc: 0.8207\nEpoch 11/100\nTrain Loss: 0.3798, Train Acc: 0.8349\nTest Loss: 0.4089, Test Acc: 0.8207\nEpoch 12/100\nTrain Loss: 0.3765, Train Acc: 0.8369\nTest Loss: 0.4042, Test Acc: 0.8232\nEpoch 13/100\nTrain Loss: 0.3687, Train Acc: 0.8392\nTest Loss: 0.3893, Test Acc: 0.8207\nEpoch 14/100\nTrain Loss: 0.3633, Train Acc: 0.8413\nTest Loss: 0.4000, Test Acc: 0.8198\nEpoch 15/100\nTrain Loss: 0.3557, Train Acc: 0.8426\nTest Loss: 0.4052, Test Acc: 0.8215\nEpoch 16/100\nTrain Loss: 0.3429, Train Acc: 0.8520\nTest Loss: 0.4010, Test Acc: 0.8061\nEarly stopping at epoch 16\n\nFold 1 Results:\nAccuracy: 0.8301\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    Nonbully       0.78      0.85      0.81       500\n       Bully       0.88      0.82      0.85       671\n\n    accuracy                           0.83      1171\n   macro avg       0.83      0.83      0.83      1171\nweighted avg       0.83      0.83      0.83      1171\n\n\nConfusion Matrix:\n[[423  77]\n [122 549]]\n\n==================================================\nFOLD 2/5\n==================================================\nTraining samples: 4683, Test samples: 1171\nTraining class distribution: Img-Text-Label\nBully       2589\nNonbully    2094\nName: count, dtype: int64\nTest class distribution: Img-Text-Label\nBully       633\nNonbully    538\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-f083a802e9dc>:681: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"cyberbullying_model_fold{fold+1}_best.pth\"))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\nTrain Loss: 0.4788, Train Acc: 0.7826\nTest Loss: 0.4737, Test Acc: 0.7848\nModel saved with test accuracy: 0.7848\nEpoch 2/100\nTrain Loss: 0.4097, Train Acc: 0.8202\nTest Loss: 0.4132, Test Acc: 0.8224\nModel saved with test accuracy: 0.8224\nEpoch 3/100\nTrain Loss: 0.3996, Train Acc: 0.8240\nTest Loss: 0.4154, Test Acc: 0.8164\nEpoch 4/100\nTrain Loss: 0.3999, Train Acc: 0.8258\nTest Loss: 0.4138, Test Acc: 0.8241\nModel saved with test accuracy: 0.8241\nEpoch 5/100\nTrain Loss: 0.3961, Train Acc: 0.8281\nTest Loss: 0.4156, Test Acc: 0.8173\nEpoch 6/100\nTrain Loss: 0.3909, Train Acc: 0.8247\nTest Loss: 0.4092, Test Acc: 0.8309\nModel saved with test accuracy: 0.8309\nEpoch 7/100\nTrain Loss: 0.3893, Train Acc: 0.8290\nTest Loss: 0.4168, Test Acc: 0.8207\nEpoch 8/100\nTrain Loss: 0.3879, Train Acc: 0.8315\nTest Loss: 0.4097, Test Acc: 0.8224\nEpoch 9/100\nTrain Loss: 0.3850, Train Acc: 0.8309\nTest Loss: 0.4085, Test Acc: 0.8232\nEpoch 10/100\nTrain Loss: 0.3778, Train Acc: 0.8290\nTest Loss: 0.4123, Test Acc: 0.8284\nEpoch 11/100\nTrain Loss: 0.3772, Train Acc: 0.8345\nTest Loss: 0.4125, Test Acc: 0.8258\nEpoch 12/100\nTrain Loss: 0.3696, Train Acc: 0.8345\nTest Loss: 0.4259, Test Acc: 0.8190\nEpoch 13/100\nTrain Loss: 0.3608, Train Acc: 0.8413\nTest Loss: 0.4204, Test Acc: 0.8284\nEpoch 14/100\nTrain Loss: 0.3583, Train Acc: 0.8405\nTest Loss: 0.4198, Test Acc: 0.8266\nEpoch 15/100\nTrain Loss: 0.3511, Train Acc: 0.8422\nTest Loss: 0.4206, Test Acc: 0.8258\nEpoch 16/100\nTrain Loss: 0.3418, Train Acc: 0.8469\nTest Loss: 0.4404, Test Acc: 0.8138\nEarly stopping at epoch 16\n\nFold 2 Results:\nAccuracy: 0.8309\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    Nonbully       0.81      0.82      0.82       538\n       Bully       0.85      0.84      0.84       633\n\n    accuracy                           0.83      1171\n   macro avg       0.83      0.83      0.83      1171\nweighted avg       0.83      0.83      0.83      1171\n\n\nConfusion Matrix:\n[[443  95]\n [103 530]]\n\n==================================================\nFOLD 3/5\n==================================================\nTraining samples: 4683, Test samples: 1171\nTraining class distribution: Img-Text-Label\nBully       2566\nNonbully    2117\nName: count, dtype: int64\nTest class distribution: Img-Text-Label\nBully       656\nNonbully    515\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-f083a802e9dc>:681: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"cyberbullying_model_fold{fold+1}_best.pth\"))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\nTrain Loss: 0.4731, Train Acc: 0.7841\nTest Loss: 0.3935, Test Acc: 0.8275\nModel saved with test accuracy: 0.8275\nEpoch 2/100\nTrain Loss: 0.4134, Train Acc: 0.8166\nTest Loss: 0.3962, Test Acc: 0.8309\nModel saved with test accuracy: 0.8309\nEpoch 3/100\nTrain Loss: 0.4078, Train Acc: 0.8240\nTest Loss: 0.4086, Test Acc: 0.8275\nEpoch 4/100\nTrain Loss: 0.4054, Train Acc: 0.8213\nTest Loss: 0.4015, Test Acc: 0.8266\nEpoch 5/100\nTrain Loss: 0.4025, Train Acc: 0.8232\nTest Loss: 0.3920, Test Acc: 0.8301\nEpoch 6/100\nTrain Loss: 0.3982, Train Acc: 0.8247\nTest Loss: 0.3874, Test Acc: 0.8343\nModel saved with test accuracy: 0.8343\nEpoch 7/100\nTrain Loss: 0.3935, Train Acc: 0.8240\nTest Loss: 0.3880, Test Acc: 0.8369\nModel saved with test accuracy: 0.8369\nEpoch 8/100\nTrain Loss: 0.3916, Train Acc: 0.8296\nTest Loss: 0.3854, Test Acc: 0.8318\nEpoch 9/100\nTrain Loss: 0.3917, Train Acc: 0.8240\nTest Loss: 0.3847, Test Acc: 0.8386\nModel saved with test accuracy: 0.8386\nEpoch 10/100\nTrain Loss: 0.3884, Train Acc: 0.8307\nTest Loss: 0.3892, Test Acc: 0.8301\nEpoch 11/100\nTrain Loss: 0.3839, Train Acc: 0.8302\nTest Loss: 0.3937, Test Acc: 0.8318\nEpoch 12/100\nTrain Loss: 0.3832, Train Acc: 0.8296\nTest Loss: 0.3905, Test Acc: 0.8326\nEpoch 13/100\nTrain Loss: 0.3756, Train Acc: 0.8347\nTest Loss: 0.3895, Test Acc: 0.8258\nEpoch 14/100\nTrain Loss: 0.3731, Train Acc: 0.8356\nTest Loss: 0.3878, Test Acc: 0.8335\nEpoch 15/100\nTrain Loss: 0.3678, Train Acc: 0.8366\nTest Loss: 0.3925, Test Acc: 0.8301\nEpoch 16/100\nTrain Loss: 0.3583, Train Acc: 0.8424\nTest Loss: 0.3957, Test Acc: 0.8284\nEpoch 17/100\nTrain Loss: 0.3524, Train Acc: 0.8454\nTest Loss: 0.4012, Test Acc: 0.8232\nEpoch 18/100\nTrain Loss: 0.3484, Train Acc: 0.8501\nTest Loss: 0.4050, Test Acc: 0.8190\nEpoch 19/100\nTrain Loss: 0.3375, Train Acc: 0.8518\nTest Loss: 0.3971, Test Acc: 0.8301\nEarly stopping at epoch 19\n\nFold 3 Results:\nAccuracy: 0.8386\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    Nonbully       0.81      0.82      0.82       515\n       Bully       0.86      0.85      0.86       656\n\n    accuracy                           0.84      1171\n   macro avg       0.84      0.84      0.84      1171\nweighted avg       0.84      0.84      0.84      1171\n\n\nConfusion Matrix:\n[[424  91]\n [ 98 558]]\n\n==================================================\nFOLD 4/5\n==================================================\nTraining samples: 4683, Test samples: 1171\nTraining class distribution: Img-Text-Label\nBully       2582\nNonbully    2101\nName: count, dtype: int64\nTest class distribution: Img-Text-Label\nBully       640\nNonbully    531\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-f083a802e9dc>:681: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"cyberbullying_model_fold{fold+1}_best.pth\"))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\nTrain Loss: 0.4914, Train Acc: 0.7634\nTest Loss: 0.4597, Test Acc: 0.7925\nModel saved with test accuracy: 0.7925\nEpoch 2/100\nTrain Loss: 0.4171, Train Acc: 0.8097\nTest Loss: 0.4423, Test Acc: 0.8019\nModel saved with test accuracy: 0.8019\nEpoch 3/100\nTrain Loss: 0.4107, Train Acc: 0.8219\nTest Loss: 0.4073, Test Acc: 0.8147\nModel saved with test accuracy: 0.8147\nEpoch 4/100\nTrain Loss: 0.4006, Train Acc: 0.8245\nTest Loss: 0.4112, Test Acc: 0.8104\nEpoch 5/100\nTrain Loss: 0.3976, Train Acc: 0.8283\nTest Loss: 0.4080, Test Acc: 0.8138\nEpoch 6/100\nTrain Loss: 0.3929, Train Acc: 0.8290\nTest Loss: 0.4100, Test Acc: 0.8181\nModel saved with test accuracy: 0.8181\nEpoch 7/100\nTrain Loss: 0.3901, Train Acc: 0.8296\nTest Loss: 0.4078, Test Acc: 0.8224\nModel saved with test accuracy: 0.8224\nEpoch 8/100\nTrain Loss: 0.3849, Train Acc: 0.8300\nTest Loss: 0.4042, Test Acc: 0.8181\nEpoch 9/100\nTrain Loss: 0.3817, Train Acc: 0.8337\nTest Loss: 0.4198, Test Acc: 0.8207\nEpoch 10/100\nTrain Loss: 0.3814, Train Acc: 0.8337\nTest Loss: 0.4261, Test Acc: 0.8147\nEpoch 11/100\nTrain Loss: 0.3707, Train Acc: 0.8377\nTest Loss: 0.4161, Test Acc: 0.8147\nEpoch 12/100\nTrain Loss: 0.3671, Train Acc: 0.8424\nTest Loss: 0.4103, Test Acc: 0.8113\nEpoch 13/100\nTrain Loss: 0.3630, Train Acc: 0.8439\nTest Loss: 0.4167, Test Acc: 0.8138\nEpoch 14/100\nTrain Loss: 0.3509, Train Acc: 0.8460\nTest Loss: 0.4251, Test Acc: 0.8104\nEpoch 15/100\nTrain Loss: 0.3444, Train Acc: 0.8520\nTest Loss: 0.4159, Test Acc: 0.8164\nEpoch 16/100\nTrain Loss: 0.3381, Train Acc: 0.8499\nTest Loss: 0.4337, Test Acc: 0.8096\nEpoch 17/100\nTrain Loss: 0.3264, Train Acc: 0.8559\nTest Loss: 0.4365, Test Acc: 0.8096\nEarly stopping at epoch 17\n\nFold 4 Results:\nAccuracy: 0.8224\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    Nonbully       0.81      0.79      0.80       531\n       Bully       0.83      0.85      0.84       640\n\n    accuracy                           0.82      1171\n   macro avg       0.82      0.82      0.82      1171\nweighted avg       0.82      0.82      0.82      1171\n\n\nConfusion Matrix:\n[[420 111]\n [ 97 543]]\n\n==================================================\nFOLD 5/5\n==================================================\nTraining samples: 4684, Test samples: 1170\nTraining class distribution: Img-Text-Label\nBully       2600\nNonbully    2084\nName: count, dtype: int64\nTest class distribution: Img-Text-Label\nBully       622\nNonbully    548\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-f083a802e9dc>:681: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"cyberbullying_model_fold{fold+1}_best.pth\"))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\nTrain Loss: 0.4761, Train Acc: 0.7829\nTest Loss: 0.4316, Test Acc: 0.8162\nModel saved with test accuracy: 0.8162\nEpoch 2/100\nTrain Loss: 0.4056, Train Acc: 0.8215\nTest Loss: 0.4222, Test Acc: 0.8231\nModel saved with test accuracy: 0.8231\nEpoch 3/100\nTrain Loss: 0.3979, Train Acc: 0.8222\nTest Loss: 0.4365, Test Acc: 0.8188\nEpoch 4/100\nTrain Loss: 0.3955, Train Acc: 0.8258\nTest Loss: 0.4203, Test Acc: 0.8205\nEpoch 5/100\nTrain Loss: 0.3900, Train Acc: 0.8288\nTest Loss: 0.4324, Test Acc: 0.8162\nEpoch 6/100\nTrain Loss: 0.3835, Train Acc: 0.8316\nTest Loss: 0.4179, Test Acc: 0.8197\nEpoch 7/100\nTrain Loss: 0.3802, Train Acc: 0.8318\nTest Loss: 0.4282, Test Acc: 0.8205\nEpoch 8/100\nTrain Loss: 0.3791, Train Acc: 0.8324\nTest Loss: 0.4185, Test Acc: 0.8214\nEpoch 9/100\nTrain Loss: 0.3725, Train Acc: 0.8397\nTest Loss: 0.4308, Test Acc: 0.8205\nEpoch 10/100\nTrain Loss: 0.3648, Train Acc: 0.8429\nTest Loss: 0.4406, Test Acc: 0.8145\nEpoch 11/100\nTrain Loss: 0.3594, Train Acc: 0.8442\nTest Loss: 0.4264, Test Acc: 0.8120\nEpoch 12/100\nTrain Loss: 0.3513, Train Acc: 0.8465\nTest Loss: 0.4293, Test Acc: 0.8068\nEarly stopping at epoch 12\n\nFold 5 Results:\nAccuracy: 0.8231\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    Nonbully       0.81      0.81      0.81       548\n       Bully       0.83      0.83      0.83       622\n\n    accuracy                           0.82      1170\n   macro avg       0.82      0.82      0.82      1170\nweighted avg       0.82      0.82      0.82      1170\n\n\nConfusion Matrix:\n[[445 103]\n [104 518]]\n\n==================================================\nAVERAGE RESULTS ACROSS 5 FOLDS\n==================================================\nAverage Accuracy: 0.8290\n\nAverage Classification Report:\n               precision    recall  f1-score\nNonbully       0.8045      0.8191    0.8115\nBully          0.8498      0.8375    0.8434\nmacro avg      0.8272      0.8283    0.8275\nweighted avg   0.8298      0.8290    0.8291\n\nAverage Confusion Matrix:\n[[431  95]\n [104 539]]\n\nTraining final model on full dataset...\nTraining samples: 4683, Test samples: 1171\nTraining class distribution: Img-Text-Label\nBully       2577\nNonbully    2106\nName: count, dtype: int64\nTest class distribution: Img-Text-Label\nBully       645\nNonbully    526\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-f083a802e9dc>:681: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(f\"cyberbullying_model_fold{fold+1}_best.pth\"))\n","output_type":"stream"},{"name":"stdout","text":"Using metadata dimension: 7\nEpoch 1/100\nTrain Loss: 0.4815, Train Acc: 0.7798\nTest Loss: 0.4099, Test Acc: 0.8138\nModel saved with test accuracy: 0.8138\nEpoch 2/100\nTrain Loss: 0.4116, Train Acc: 0.8196\nTest Loss: 0.4035, Test Acc: 0.8181\nModel saved with test accuracy: 0.8181\nEpoch 3/100\nTrain Loss: 0.4046, Train Acc: 0.8253\nTest Loss: 0.4104, Test Acc: 0.8215\nModel saved with test accuracy: 0.8215\nEpoch 4/100\nTrain Loss: 0.4025, Train Acc: 0.8264\nTest Loss: 0.4088, Test Acc: 0.8096\nEpoch 5/100\nTrain Loss: 0.3971, Train Acc: 0.8285\nTest Loss: 0.4503, Test Acc: 0.8053\nEpoch 6/100\nTrain Loss: 0.3965, Train Acc: 0.8305\nTest Loss: 0.4060, Test Acc: 0.8164\nEpoch 7/100\nTrain Loss: 0.3910, Train Acc: 0.8305\nTest Loss: 0.4072, Test Acc: 0.8207\nEpoch 8/100\nTrain Loss: 0.3893, Train Acc: 0.8285\nTest Loss: 0.4071, Test Acc: 0.8104\nEpoch 9/100\nTrain Loss: 0.3866, Train Acc: 0.8294\nTest Loss: 0.4054, Test Acc: 0.8147\nEpoch 10/100\nTrain Loss: 0.3811, Train Acc: 0.8332\nTest Loss: 0.4144, Test Acc: 0.8087\nEpoch 11/100\nTrain Loss: 0.3784, Train Acc: 0.8377\nTest Loss: 0.4095, Test Acc: 0.8207\nEpoch 12/100\nTrain Loss: 0.3746, Train Acc: 0.8371\nTest Loss: 0.4195, Test Acc: 0.8113\nEpoch 13/100\nTrain Loss: 0.3703, Train Acc: 0.8396\nTest Loss: 0.4146, Test Acc: 0.8121\nEarly stopping at epoch 13\n\nFinal Test Results:\nAccuracy: 0.8215\n\nClassification Report:\n              precision    recall  f1-score   support\n\n    Nonbully       0.78      0.85      0.81       526\n       Bully       0.86      0.80      0.83       645\n\n    accuracy                           0.82      1171\n   macro avg       0.82      0.82      0.82      1171\nweighted avg       0.83      0.82      0.82      1171\n\n\nConfusion Matrix:\n[[445  81]\n [128 517]]\nFinal model saved to cyberbullying_model_final.pth\nTraining and evaluation complete!\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-f083a802e9dc>:478: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"cyberbullying_model_best.pth\"))\n","output_type":"stream"}],"execution_count":1}]}